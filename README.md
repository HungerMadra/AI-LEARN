Building a Large Language Model from Scratch - Follow Along

ğŸ“Œ About This Repository

This repository documents my journey as I study "Building a Large Language Model from Scratch" by Sebastian Raschka. I am implementing the concepts and coding exercises as I progress through the material, sharing my insights, challenges, and learnings along the way.

ğŸš€ Objectives

Gain a deep understanding of how LLMs are built from the ground up.

Implement core components of an LLM, including tokenization, embedding layers, and transformer architectures.

Experiment with different training techniques and optimizations.

Share my code, findings, and notes to help others who are on the same journey.

ğŸ“– Topics Covered

As I progress, I'll be updating this section with key topics Iâ€™ve implemented:

Understanding Tensors & PyTorch Basics âœ…

Tokenization & Preprocessing ğŸ”„ (In Progress)

Building the Neural Network Foundations

Implementing Attention Mechanisms

Transformers & Self-Attention

Training & Fine-Tuning an LLM

Deploying & Evaluating the Model

ğŸ›  How to Use This Repo

Clone the repository

git clone https://github.com/HungerMadra/AI-LEARN
cd llm-from-scratch

Follow along with the notebooks/ directory for Jupyter notebooks containing step-by-step implementations.

Refer to scripts/ for Python scripts covering core functionalities.

Check out my notes in docs/ for explanations and additional insights.

ğŸ¤ Contributions & Feedback

This is a learning-focused project, and I welcome feedback, discussions, and contributions! Feel free to open an issue or reach out.

ğŸ“Œ Acknowledgments

Sebastian Raschka for the incredible book and course materials.

The AI/ML community for sharing knowledge and insights.

ğŸš€ Follow my journey as I build a working LLM from scratch!
